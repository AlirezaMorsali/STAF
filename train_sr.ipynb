{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "from modules import utils\n",
    "from modules.models import INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='STAF super resolution')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='./data/Image/0882.png', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='staf', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode, finer, staf]')\n",
    "parser.add_argument('--lr',type=float, default=1e-3, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.1, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=16*16, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=501, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=100, help='Number of steps till summary visualization')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help='Upscale factor for super-resolution (e.g., 4x larger output)')\n",
    "parser.add_argument('--eval_epoch', type=int, default=400, help='HR evaluation epoch')\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image hr: 1356, 2040\n",
      "image lr: 339, 510\n"
     ]
    }
   ],
   "source": [
    "im_hr = utils.normalize(plt.imread(args.input).astype(np.float32), True)\n",
    "im_lr = cv2.resize(im_hr, None, fx=1/args.upscale_factor, fy=1/args.upscale_factor, interpolation=cv2.INTER_AREA)\n",
    "H_hr, W_hr, _ = im_hr.shape\n",
    "H_lr, W_lr, _ = im_lr.shape\n",
    "\n",
    "print(f'image hr: {H_hr}, {W_hr}')\n",
    "print(f'image lr: {H_lr}, {W_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': int(max(H_lr, W_lr))}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Configurations for STAF\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3,\n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0\n",
    "                               ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and SSIM\n",
    "psnr_values_lr = []\n",
    "psnr_values_hr = []\n",
    "ssim_values_hr = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords_lr = utils.get_coords(H_lr, W_lr, dim=2)[None, ...]\n",
    "coords_hr = utils.get_coords(H_hr, W_hr, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt_lr = torch.tensor(im_lr).reshape(H_lr * W_lr, 3)[None, ...].to(device)\n",
    "gt_hr = torch.tensor(im_hr).reshape(H_hr * W_hr, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec_lr = torch.zeros_like(gt_lr)\n",
    "rec_hr = torch.zeros_like(gt_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a452e7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d91fe9af641426ebefc99709b8ca203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 41\u001b[0m     \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Calculate and log mean squared error (MSE) and PSNR\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml/lib/python3.13/site-packages/torch/optim/adam.py:621\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Use device beta1 if beta1 is a tensor to ensure all\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# tensors are on the same device\u001b[39;00m\n\u001b[1;32m    619\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m device_beta1)\n\u001b[0;32m--> 621\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# Due to the strictness of the _foreach_addcmul API, we can't have a single\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;66;03m# tensor scalar as the scalar arg (only python number is supported there)\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m# as a result, separate out the value mul\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;66;03m# Filed https://github.com/pytorch/pytorch/issues/139795\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H_lr*W_lr)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H_lr*W_lr, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H_lr*W_lr, b_idx+args.maxpoints)]\n",
    "        b_coords = coords_lr[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "\n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)\n",
    "        else:\n",
    "            model_output = model(b_coords)\n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec_lr[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_lr[:, b_indices, :])**2).mean()\n",
    "\n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]\n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                       args.b_coef * torch.relu(-b_coef) + \\\n",
    "                       args.c_coef * torch.relu(-c_coef) + \\\n",
    "                       args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss\n",
    "        else:\n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt_lr - rec_lr)**2).mean().item()\n",
    "        psnr_lr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values_lr.append(psnr_lr.item())\n",
    "\n",
    "        #### HR Evaluation\n",
    "        if step > args.eval_epoch:\n",
    "            indices_hr = torch.randperm(H_hr*W_hr)\n",
    "            for b_idx in range(0, H_hr*W_hr, args.maxpoints):\n",
    "                b_indices_hr = indices_hr[b_idx:min(H_hr*W_hr, b_idx+args.maxpoints)]\n",
    "                b_coords_hr = coords_hr[:, b_indices_hr, ...].to(device)\n",
    "                b_indices_hr = b_indices_hr.to(device)\n",
    "\n",
    "                if args.inr_model == 'incode':\n",
    "                    model_eval, _ = model(b_coords_hr)\n",
    "                else:\n",
    "                    model_eval = model(b_coords_hr)\n",
    "\n",
    "                rec_hr[:, b_indices_hr, :] = model_eval\n",
    "\n",
    "            loss_hr = ((gt_hr - rec_hr)**2).mean()\n",
    "            psnr_hr = -10*torch.log10(loss_hr)\n",
    "            psnr_values_hr.append(psnr_hr.item())\n",
    "            hr_pred = rec_hr[0, ...].reshape(H_hr, W_hr, 3).detach().cpu().numpy()\n",
    "            hr_pred = (hr_pred - hr_pred.min()) / (hr_pred.max() - hr_pred.min())\n",
    "\n",
    "            # Check if the current iteration's HR image is the best so far\n",
    "            if (loss_hr < best_loss) or (step == args.eval_epoch+1):\n",
    "                best_loss = loss_hr\n",
    "                best_img_hr = hr_pred\n",
    "                best_img_lr = rec_lr[0, ...].reshape(H_lr, W_lr, 3).detach().cpu().numpy()\n",
    "                best_img_lr = (best_img_lr - best_img_lr.min()) / (best_img_lr.max() - best_img_lr.min())\n",
    "\n",
    "                ### Plot\n",
    "                fig, axes = plt.subplots(1, 4, figsize=(9, 9))\n",
    "                subplot_info = [\n",
    "                    {'title': 'GT HR', 'image': im_hr},\n",
    "                    {'title': 'HR Image', 'image': best_img_hr},\n",
    "                    {'title': 'GT LR', 'image': im_lr},\n",
    "                    {'title': 'LR Image', 'image': best_img_lr}\n",
    "                ]\n",
    "\n",
    "                for ax, info in zip(axes, subplot_info):\n",
    "                    ax.set_title(info['title'])\n",
    "                    ax.imshow(info['image'], cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "              # SSIM\n",
    "            ms_ssim_val = ssim(torch.tensor(im_hr[None,...]).permute(0, 3, 1, 2),\n",
    "                                torch.tensor(hr_pred[None, ...]).permute(0, 3, 1, 2),\n",
    "                                data_range=1, size_average=False)\n",
    "            ssim_values_hr.append(ms_ssim_val[0].item())\n",
    "\n",
    "            # Display intermediate results at specified intervals\n",
    "            print(\"Epoch: {} | Total Loss: {:.5f} | PSNR LR: {:.4f} | PSNR HR: {:.4f} | SSIM: {:.4f}\".format(step,\n",
    "                                                                                                  mse_array[step].item(),\n",
    "                                                                                                  psnr_lr.item(),\n",
    "                                                                                                  psnr_hr.item(),\n",
    "                                                                                                  ms_ssim_val[0].item()))\n",
    "\n",
    "        # Display intermediate results at specified intervals\n",
    "        if (step % args.steps_til_summary == 0) and step <= args.eval_epoch:\n",
    "            print(\"Epoch: {} | Total Loss: {:.5f} | PSNR LR: {:.4f}\".format(step,\n",
    "                                                                             mse_array[step].item(),\n",
    "                                                                             psnr_lr.item()))\n",
    "\n",
    "    # Adjust learning rate using a sch.duler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR LR:', max(psnr_values_lr))\n",
    "print('Max PSNR HR:', max(psnr_values_hr))\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PSNR LR vs. #Epochs\n",
    "## PSNR HR vs. #Epochs\n",
    "## SSIM vs. #Epochs\n",
    "\n",
    "\n",
    "# Define the font settings\n",
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "axfont = {'family': 'Times New Roman', 'weight': 'regular', 'size': 10}\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "# Plot PSNR LR vs. #Epochs\n",
    "axes[0].plot(np.arange(len(psnr_values_lr[:-1])), psnr_values_lr[:-1], label=f\"{(args.inr_model).upper()}\")\n",
    "axes[0].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[0].set_ylabel('PSNR (dB)', fontdict=font)\n",
    "axes[0].set_title('PSNR LR vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, color='lightgray')\n",
    "\n",
    "# Plot PSNR HR vs. #Epochs\n",
    "axes[1].plot(np.arange(len(psnr_values_hr[:-1])), psnr_values_hr[:-1], label=f\"{(args.inr_model).upper()}\", color='black')\n",
    "axes[1].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[1].set_ylabel('PSNR (dB)', fontdict=font)\n",
    "axes[1].set_title('PSNR HR vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, color='lightgray')\n",
    "\n",
    "# Plot SSIM vs. #Epochs\n",
    "axes[2].plot(np.arange(len(ssim_values_hr[:-1])), ssim_values_hr[:-1], label=f\"{(args.inr_model).upper()}\", color='red')\n",
    "axes[2].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[2].set_ylabel('SSIM', fontdict=font)\n",
    "axes[2].set_title('SSIM vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, color='lightgray')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605a862-d999-461f-a1a8-eb79c7e1a7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0763deb7509549fc8942593083cb3c64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "09486602764e4dc9a23be0cd3c6e5ffd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_45b6ad514f01430dbdecd6cc54908f4d",
       "style": "IPY_MODEL_3c820219215f4200809f18cc7c6fac20",
       "value": " 0/501 [00:15&lt;?, ?it/s]"
      }
     },
     "0b9bd90131f14966a4aebb7f42704aea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d8038ff9ccb4a409f95bad5477e4bc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1447dc94dd42486289ebae5fd31773c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1d91fe9af641426ebefc99709b8ca203": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_29ffdfff32a94da5b796164827723cbc",
        "IPY_MODEL_6f582f5716384fd08738602020d73099",
        "IPY_MODEL_09486602764e4dc9a23be0cd3c6e5ffd"
       ],
       "layout": "IPY_MODEL_b57dbb9e8dcb48789205fd7569b717b6"
      }
     },
     "1fa99396189744ce91047d110d48566a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "29ffdfff32a94da5b796164827723cbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4dca98eeef68466fbbb426f781b12afc",
       "style": "IPY_MODEL_2af006d7c40649dd9debf2b53a25f2f7",
       "value": "  0%"
      }
     },
     "2af006d7c40649dd9debf2b53a25f2f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2b133ff912244842a0d3ed0e8cc663cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_3ad25d7e59a548fb94325ba44ecbda68",
       "max": 501,
       "style": "IPY_MODEL_d49e53f77fb24e05822f3429c03f0775",
       "value": 7
      }
     },
     "34d478650f2a4033b369670377745516": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3ad25d7e59a548fb94325ba44ecbda68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3c820219215f4200809f18cc7c6fac20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4497fc1d2ef649ba9e0ef79fbcd9162b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45b6ad514f01430dbdecd6cc54908f4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "479d1929a4ad4898ad50a079e5be5979": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f7753c95d3fd45a99a8c68b35cc8deba",
       "style": "IPY_MODEL_a75930537d6e4b178538670d7b99a663",
       "value": " 7/501 [00:19&lt;20:03,  2.44s/it]"
      }
     },
     "4dca98eeef68466fbbb426f781b12afc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "57d300f913044611aafe1ce5918e6875": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4497fc1d2ef649ba9e0ef79fbcd9162b",
       "style": "IPY_MODEL_1fa99396189744ce91047d110d48566a",
       "value": "  1%"
      }
     },
     "585bb5fca98b41828838970f22f88db3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "60bdf2ecf5104a8c81656b64bf490766": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "694319d3c13a4aa2a0c4a22387a1c078": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_0b9bd90131f14966a4aebb7f42704aea",
       "max": 501,
       "style": "IPY_MODEL_34d478650f2a4033b369670377745516",
       "value": 7
      }
     },
     "6f582f5716384fd08738602020d73099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_585bb5fca98b41828838970f22f88db3",
       "max": 501,
       "style": "IPY_MODEL_9c505910cbc14fdc8c9d976885a933b5"
      }
     },
     "74fc9fb323de49bc924bbced05488b2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_57d300f913044611aafe1ce5918e6875",
        "IPY_MODEL_694319d3c13a4aa2a0c4a22387a1c078",
        "IPY_MODEL_d7301ee205504bdabe37fa21e6af2cee"
       ],
       "layout": "IPY_MODEL_0d8038ff9ccb4a409f95bad5477e4bc2"
      }
     },
     "753b54836ae34df1ac66a69e5f4003e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7e577c3af83b4800ad5f77af2aee9df2",
        "IPY_MODEL_2b133ff912244842a0d3ed0e8cc663cb",
        "IPY_MODEL_479d1929a4ad4898ad50a079e5be5979"
       ],
       "layout": "IPY_MODEL_0763deb7509549fc8942593083cb3c64"
      }
     },
     "7e577c3af83b4800ad5f77af2aee9df2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_60bdf2ecf5104a8c81656b64bf490766",
       "style": "IPY_MODEL_1447dc94dd42486289ebae5fd31773c2",
       "value": "  1%"
      }
     },
     "9c505910cbc14fdc8c9d976885a933b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a1ec4d49c923449985622e797212fc48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a75930537d6e4b178538670d7b99a663": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b57dbb9e8dcb48789205fd7569b717b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b75d3f6b1392486082e981c9dc731f4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d49e53f77fb24e05822f3429c03f0775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d7301ee205504bdabe37fa21e6af2cee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b75d3f6b1392486082e981c9dc731f4c",
       "style": "IPY_MODEL_a1ec4d49c923449985622e797212fc48",
       "value": " 7/501 [00:11&lt;13:14,  1.61s/it]"
      }
     },
     "f7753c95d3fd45a99a8c68b35cc8deba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
